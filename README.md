# MListheroxx

This repo is meant for a self progress record. I will keep updating it with the posts, topics and websites I refer to in order to learn new concepts, codes and various other things in the field of Data Science, ML and AI.

### Useful links that I find while studying ML and AI

### Date:- 07/02/2019

* [NIN(Network In Network](http://teleported.in/posts/network-in-network/) 
   
   Had an explanation of MLPConv and Global Average Pooling in it. 
  
* [Implementation of Dropout and it explanation](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/   )

   This explains the concept of Dropout Layers, a recent finding, that seems to increase the general performance of Deep Learning models. The 
   basic idea is to drop random nodes in a particular layer so as to generalize the performance of each parameter and not create a bias 
   performance. The following link has the code as well.

* [Convolution NN for Visual Recognition CS231n](http://cs231n.github.io/convolutional-networks/#pool)

  This has a complete explanation with Math about the different types of CNN Layers, CNN Architecture and additional references. 

### Date:- 08/02/2019

* [Softmax Classifier](https://www.pyimagesearch.com/2016/09/12/softmax-classifiers-explained/)

   This explains the difference between Softmax Classifier and the Cross entropy function. Cross entropy function uses the softmax expression
   to evaluate the loss function value. The following link also has the implementation of Softmax classifier. Keras uses a direct function
   for setting the optimizer. 
   
* [Comprehensive Guide to CNN](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)

   This very neatly and briefly explains about the various layers of a classical CNN and how things work out in one. You might well get a
   beautiful understanding of many of the basic terms in CNN.

### Date:- 10/02/2019

*  [Why is bias necessary in ANN](https://stackoverflow.com/questions/7175099/why-the-bias-is-necessary-in-ann-should-we-have-separate-bias-for-each-layer)
   
   This has a pretty good answer as to why we need to include bias in ANN.

### Date:- 11/02/2019

* [Everything you need to know about NN](https://medium.com/ravenprotocol/everything-you-need-to-know-about-neural-networks-6fcc7a15cb4)

   It gives a pretty good explanation of most of the topics that one would encounter in the field of NN. 
   
### Date:- 13/02/2019

* [A brief view of machine learning pipeline in python](https://medium.com/@yanhann10/a-brief-view-of-machine-learning-pipeline-in-python-5f50b941fca8) 

   I learnt a new concept of pipelining in Python where we can create a structure to implement various algorithms back to back in a
   pipeline form. 

### Date:- 14/02/2019

* [Primer for learning Google Colab](https://medium.com/dair-ai/primer-for-learning-google-colab-bb4cabca5dd6)

   This is a very good site to learn Google Colab! Do visit it!
   
### Date:- 16/02/2019   

* [Simple NN from Scratch](https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0)

   Simple implementation of NN with Pytorch. 
   
### Date:- 17/02/2019

* [A detailed look into the top three activation functions](https://link.medium.com/cNOrhEkJnU)

   A good lookthrough at the reasons behind choosing one of the three top 3 activation functions. 

### Date:- 18/02/2019

* [Introduction to Pytorch](https://medium.com/deeplearningbrasilia/deep-learning/-introduction-to-pytorch-5bd39421c84)

### Date:- 19/02/2019

* [How to build a Neural Network with Keras](https://towardsdatascience.com/how-to-build-a-neural-network-with-keras-e8faa33d0ae4)

   Creating a NN using IMDB dataset in Keras.
