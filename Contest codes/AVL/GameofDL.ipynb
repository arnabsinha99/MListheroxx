{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GameofDL.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB2KD8xqr9GB",
        "colab_type": "code",
        "outputId": "db731c3a-1008-48b9-9976-c25b2e2fd11a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "train_path = tf.keras.utils.get_file(\"train.csv\",\"https://datahack.analyticsvidhya.com/contest/game-of-deep-learning/download/train-file\", extract = True)\n",
        "data_root = pathlib.Path(train_path)\n",
        "p = pathlib.Path(r'C:\\Users\\Arnab Sinha\\Desktop\\BAAPFOLDER\\Datasets\\Game of DL - AV\\images')\n",
        "classes = {'Cargo':0,'Military':1,'Carrier':2,'Cruise':3,'Tankers':4}\n",
        "traincsv = pd.read_csv(r'C:\\Users\\Arnab Sinha\\Desktop\\BAAPFOLDER\\Datasets\\Game of DL - AV\\train.csv')\n",
        "ail = list(traincsv['category'].values)\n",
        "ail = [a-1 for a in ail]\n",
        "image_csv = list(traincsv['image'].values)\n",
        "# for x in range(len(ail)):\n",
        "#     print(image_csv[x],' ',ail[x])\n",
        "print(len(ail))\n",
        "oka = [item.split('.jpg') for item in image_csv]\n",
        "oka = [oka[item][0] for item in range(len(oka))]\n",
        "aip_train = ['C:\\\\Users\\\\Arnab Sinha\\\\Desktop\\\\BAAPFOLDER\\\\Datasets\\\\Game of DL - AV\\\\images\\\\' + item + '.jpg' for item in oka]\n",
        "type(aip_train[0])\n",
        "\n",
        "aip = list(p.glob('*/'))\n",
        "aip = [str(path) for path in aip]\n",
        "\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(aip_train)\n",
        "# print(path_ds.take(4))\n",
        "\n",
        "# print(path_ds)\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "  image = tf.io.read_file(path)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.resize(image, [160,160])\n",
        "  image/=255.0\n",
        "  return image\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# sample = tf.io.read_file('C:\\\\Users\\\\Arnab Sinha\\\\Desktop\\\\BAAPFOLDER\\\\Datasets\\\\Game of DL - AV\\\\images\\\\1001524.jpg')\n",
        "# sample = tf.image.decode_jpeg(sample,channels = 3)\n",
        "# print(sample.shape)\n",
        "\n",
        "import re\n",
        "\n",
        "image_n = [re.findall(\"[0-9][0-9]*\",str) for str in aip]\n",
        "image_no = []\n",
        "for item in image_n:\n",
        "    image_no.append(item[0])\n",
        "image_no\n",
        "\n",
        "diff = list(set(image_no)-set(oka))\n",
        "\n",
        "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(ail, tf.int64))\n",
        "\n",
        "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
        "\n",
        "print(image_label_ds)\n",
        "\n",
        "image_count = len(aip_train)\n",
        "\n",
        "image_count\n",
        "\n",
        "ds = tf.data.Dataset.from_tensor_slices((aip_train, ail))\n",
        "\n",
        "# The tuples are unpacked into the positional arguments of the mapped function\n",
        "def load_and_preprocess_from_path_label(path, label):\n",
        "  return load_and_preprocess_image(path), label\n",
        "\n",
        "image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
        "image_label_ds\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "ds = image_label_ds.cache()\n",
        "ds = ds.apply(\n",
        "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
        "ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "ds\n",
        "\n",
        "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(160, 160, 3), include_top=False)\n",
        "mobile_net.trainable=False\n",
        "\n",
        "def change_range(image,label):\n",
        "  return 2*image-1, label\n",
        "\n",
        "keras_ds = ds.map(change_range)\n",
        "\n",
        "# The dataset may take a few seconds to start, as it fills its shuffle buffer.\n",
        "image_batch, label_batch = next(iter(keras_ds))\n",
        "\n",
        "label_names = [0,1,2,3,4]\n",
        "model = tf.keras.Sequential([\n",
        "  mobile_net,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(len(label_names))])\n",
        "\n",
        "logit_batch = model(image_batch).numpy()\n",
        "\n",
        "print(\"min logit:\", logit_batch.min())\n",
        "print(\"max logit:\", logit_batch.max())\n",
        "print()\n",
        "\n",
        "print(\"Shape:\", logit_batch.shape)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "steps_per_epoch=tf.math.ceil(len(aip_train)/BATCH_SIZE).numpy()\n",
        "steps_per_epoch\n",
        "\n",
        "model.fit(ds, epochs=1, steps_per_epoch=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6252\n",
            "<ZipDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)>\n",
            "min logit: -1.3205826\n",
            "max logit: 2.089417\n",
            "\n",
            "Shape: (32, 5)\n",
            "20/20 [==============================] - 162s 8s/step - loss: 3.4132 - accuracy: 0.2891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1761c0ebb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}