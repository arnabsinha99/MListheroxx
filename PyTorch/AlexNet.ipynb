{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOThYApd76OtXDLpjMmqTd8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnabsinha99/MListheroxx/blob/master/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyB7BnSjwmOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import helper\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = \"retina\"\n",
        "\n",
        "#SINCE IMAGENET IS HEAVY TO DOWNLOAD  I HAVE USED CIFAR-10 data on Alexnet, which is not recommended but for convenience of internet during Lockdown!!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VJfPpTzwq8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "21fe9e29-f0c8-4e8e-f0dc-0c5bab080ff1"
      },
      "source": [
        "transform = transforms.Compose([#transforms.ToPILImage(),\n",
        "                                transforms.Resize((227,227)),\n",
        "                                transforms.ToTensor(),\n",
        "                                ])\n",
        "train = datasets.CIFAR10(root = 'data',train = True, transform = transform, download = True)\n",
        "test = datasets.CIFAR10(root = 'data',train = False, transform = transform, download = True)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLue5a9RTttl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train = len(train)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_val_split = 0.2 # 20% validation set out of training set\n",
        "\n",
        "split = int(np.floor(train_val_split*num_train))\n",
        "train_idx,valid_idx = indices[split:],indices[:split]\n",
        "\n",
        "trainSampler = SubsetRandomSampler(train_idx)\n",
        "validSampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "num_workers = 0\n",
        "b_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ru4jY2TwOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = torch.utils.data.DataLoader(train, b_size, sampler = trainSampler, num_workers=num_workers)\n",
        "test_data = torch.utils.data.DataLoader(test, b_size, num_workers=num_workers)\n",
        "valid_data = torch.utils.data.DataLoader(train, b_size, sampler = validSampler, num_workers=num_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbzYXbHfg9Bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataiter = iter(train_data)\n",
        "\n",
        "# images, labels = next(dataiter)\n",
        "# images = images.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFSlAzSlRczJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IUkNw4KhgDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fig = plt.figure(figsize = (25,4))\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "            'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "# def imshow(img):\n",
        "#     #img = img / 2 + 0.5  # unnormalize\n",
        "#     plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
        "\n",
        "# for idx in range(b_size):\n",
        "#   ax = fig.add_subplot(2, 10, idx+1, xticks = [],yticks = [])\n",
        "#   imshow(images[idx])\n",
        "#   ax.set_title(classes[labels[idx].item()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpd25n_y0Y6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def conv_batch(images,b_size):\n",
        "#   im = []\n",
        "#   for idx in range(b_size):\n",
        "#     im.append(((images[idx][0]+images[idx][1]+images[idx][2])/3).flatten())\n",
        "#   return np.array(im).reshape((20,227,227))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_p_6OqOifmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbIYLAPjsS-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicNet(nn.Module):\n",
        "  def __init__(self, num_classes = 10):\n",
        "    super(BasicNet, self).__init__()\n",
        "    \n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),  # (b x 96 x 55 x 55)\n",
        "            nn.ReLU(),\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # section 3.3\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 96 x 27 x 27)\n",
        "            nn.Conv2d(96, 256, 5, padding=2),  # (b x 256 x 27 x 27)\n",
        "            nn.ReLU(),\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 13 x 13)\n",
        "            nn.Conv2d(256, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(384, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(384, 256, 3, padding=1),  # (b x 256 x 13 x 13)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 6 x 6)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.5,inplace = True),\n",
        "        nn.Linear(in_features = (256*6*6),out_features = 4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5,inplace = True),\n",
        "        nn.Linear(in_features = 4096,out_features = 4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=4096, out_features=num_classes)\n",
        "    )\n",
        "\n",
        "    self.init_bias()\n",
        "  \n",
        "  def init_bias(self):\n",
        "    for layer in self.net:\n",
        "      if isinstance(layer, nn.Conv2d):\n",
        "        nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
        "        nn.init.constant_(layer.bias, 0)\n",
        "    nn.init.constant_(self.net[4].bias, 1)\n",
        "    nn.init.constant_(self.net[10].bias, 1)\n",
        "    nn.init.constant_(self.net[12].bias, 1)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = self.net(x)\n",
        "\n",
        "    x = x.view(-1,256*6*6)\n",
        "    return self.classifier(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaqnNNBB8PjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 5  # original paper\n",
        "BATCH_SIZE = 100\n",
        "MOMENTUM = 0.9\n",
        "LR_DECAY = 0.0005\n",
        "LR_INIT = 0.01\n",
        "IMAGE_DIM = 227  # pixels\n",
        "NUM_CLASSES = 10  # 1000 classes in original paper for ImageNet\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "a = BasicNet(num_classes=NUM_CLASSES).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQE_2FPgBdpc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "36324358-8eb2-4fd4-b11a-14aa2a9c7b82"
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "train_on_gpu"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVOk5v4v3_AL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Optimizer\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(a.parameters(),lr = 0.01)\n",
        "optimizer = optim.SGD(a.parameters(),lr = LR_INIT,momentum = MOMENTUM, weight_decay=LR_DECAY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ1nIJEE6txG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=1,gamma = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-7r1T1v7D1m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "1ac3a787-79f1-4116-b4a1-abc8f4e08b2b"
      },
      "source": [
        "#Training\n",
        "\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  train_loss = 0.0\n",
        "  valid_loss = 0.0\n",
        "  \n",
        "  a.train()\n",
        "  #b = 0\n",
        "  for imgs,classes in train_data:\n",
        "\n",
        "    #print(\"Training batch {} ...\".format(b))\n",
        "    imgs,classes = imgs.to(device),classes.to(device)\n",
        "\n",
        "    output = a(imgs)\n",
        "    loss = criterion(output,classes)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()*imgs.size(0)\n",
        "    #b+=1\n",
        "\n",
        "  print(\"Training done for Epoch {}\".format(epoch))\n",
        "\n",
        "  print('Evaluation started...')\n",
        "\n",
        "  a.eval()\n",
        "  for imgs, target in valid_data:\n",
        "    imgs,target = imgs.to(device),classes.to(device)\n",
        "    \n",
        "    output = a(imgs)\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    valid_loss += loss.item()*imgs.size(0)\n",
        "    \n",
        "  train_loss = train_loss/len(train_data.sampler)\n",
        "  valid_loss = valid_loss/len(valid_data.sampler)\n",
        "        \n",
        "  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
        "    \n",
        "  if valid_loss <= valid_loss_min:\n",
        "    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
        "    valid_loss_min = valid_loss\n",
        "  lr_scheduler.step()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training done for Epoch 0\n",
            "Evaluation started...\n",
            "Epoch: 0 \tTraining Loss: 2.306245 \tValidation Loss: 2.305328\n",
            "Validation loss decreased (inf --> 2.305328).  Saving model ...\n",
            "Training done for Epoch 1\n",
            "Evaluation started...\n",
            "Epoch: 1 \tTraining Loss: 2.302716 \tValidation Loss: 2.303598\n",
            "Validation loss decreased (2.305328 --> 2.303598).  Saving model ...\n",
            "Training done for Epoch 2\n",
            "Evaluation started...\n",
            "Epoch: 2 \tTraining Loss: 2.302569 \tValidation Loss: 2.303017\n",
            "Validation loss decreased (2.303598 --> 2.303017).  Saving model ...\n",
            "Training done for Epoch 3\n",
            "Evaluation started...\n",
            "Epoch: 3 \tTraining Loss: 2.302585 \tValidation Loss: 2.303158\n",
            "Training done for Epoch 4\n",
            "Evaluation started...\n",
            "Epoch: 4 \tTraining Loss: 2.302583 \tValidation Loss: 2.302472\n",
            "Validation loss decreased (2.303017 --> 2.302472).  Saving model ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVySkR-q_l4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "2fbcf036-3a41-43d3-a0ab-e33e0051ebe8"
      },
      "source": [
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "a.eval()\n",
        "for data, target in test_data:\n",
        "    data,target = imgs.to(device),target.to(device)\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = a(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(b_size):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_data.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 2.302615\n",
            "\n",
            "Test Accuracy of airplane:  0% ( 0/1000)\n",
            "Test Accuracy of automobile:  0% ( 0/1000)\n",
            "Test Accuracy of  bird: 100% (1000/1000)\n",
            "Test Accuracy of   cat:  0% ( 0/1000)\n",
            "Test Accuracy of  deer:  0% ( 0/1000)\n",
            "Test Accuracy of   dog:  0% ( 0/1000)\n",
            "Test Accuracy of  frog:  0% ( 0/1000)\n",
            "Test Accuracy of horse:  0% ( 0/1000)\n",
            "Test Accuracy of  ship:  0% ( 0/1000)\n",
            "Test Accuracy of truck:  0% ( 0/1000)\n",
            "\n",
            "Test Accuracy (Overall): 10% (1000/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}